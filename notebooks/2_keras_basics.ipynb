{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1_qWgbSrNdjn"
      },
      "source": [
        "![prova](https://camo.githubusercontent.com/906e661107a3bc03104ca5d88336d1f4b0e80fdcac65efaf7904041d371c747f/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6b657261732e696f2f696d672f6b657261732d6c6f676f2d323031382d6c617267652d313230302e706e67)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5M0crmii8Ysb"
      },
      "source": [
        "Keras is a high-level library leveraging TensorFlow as backend. It allows to build and experiment with ML models with an easy and flexible (?) interface.\n",
        "\n",
        "API Docs (go to `tf.keras`): https://www.tensorflow.org/versions\n",
        "\n",
        "Keras Guides (for specific API components): https://www.tensorflow.org/guide/keras\n",
        "\n",
        "Tutorials (cover examples of basic usage): https://www.tensorflow.org/tutorials/keras\n",
        "\n",
        "**Warning:** in general, it is better to use Keras whenever it is possible, since it exploits compiled computational graphs, making it way more efficent than TensorFlow (with eager execution activated, which is the default behaviour)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Q3zv6RjiUt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras as K\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y6WrRhvgA9x3",
        "outputId": "3c5ca909-663a-47c7-d868-2fc1b3c00852"
      },
      "outputs": [],
      "source": [
        "K.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UVVH9-QcC9wT",
        "outputId": "744d73a1-b537-4872-f27d-08ce47898ea8"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = K.datasets.mnist.load_data(path='ds')\n",
        "train_X, eval_X, train_y, eval_y = train_test_split(\n",
        "    train_X, train_y,\n",
        "    test_size=0.15,\n",
        "    shuffle=True,\n",
        "    stratify=train_y\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qjdGEixplbmc"
      },
      "source": [
        "# Three interfaces for building a Model on Keras\n",
        "\n",
        "Now we will see how to solve the same problem we've seen before with these three interfaces."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "26UpaZ7A9E3V"
      },
      "source": [
        "## Sequential API\n",
        "\n",
        "Everything is wrapped within the ``K.Sequential()`` \"box\", and all the objects that you add to this box are considered layers. Note that, here, a layer is not necessarily a neural layer, but whatever applies a transformation to the output of the previous layer (or to the input data).\n",
        "\n",
        "In general, you can consider the K.Sequential() interface as a wrapper for the pipeline which applies all the subsequent transformations to your input data, ending to the prediction of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alvksVvWk4vs"
      },
      "outputs": [],
      "source": [
        "seq_model = K.Sequential()\n",
        "\n",
        "seq_model.add(K.layers.Flatten())\n",
        "seq_model.add(K.layers.Rescaling(scale=1./255))\n",
        "seq_model.add(K.layers.Dense(10, activation='softmax')) # Where's the input dimension?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functional API\n",
        "\n",
        "In the Functional API, you explicitly create the pipeline we discussed before by performing subsequent applications of all the functions, __starting from a placeholder defining the input tensor__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = K.Input(shape=(28, 28)) # Implicitly, the shape will be (None, 28, 28)\n",
        "flattened = K.layers.Flatten()(inputs)\n",
        "rescaled = K.layers.Rescaling(scale=1/255.)(flattened)\n",
        "outputs = K.layers.Dense(units=10, activation='softmax')(rescaled)\n",
        "fn_model = K.Model(inputs=inputs, outputs=outputs)\n",
        "fn_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K.Model API\n",
        "\n",
        "This is the best chance you have to exploit the synergy between Keras and TensorFlow. You can define your own custom model by inheriting from the class ``K.Model``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleLinearClassifier(K.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = K.layers.Flatten()\n",
        "        self.dense = K.layers.Dense(units=10, activation='softmax')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = x / 255.\n",
        "        return self.dense(x)\n",
        "\n",
        "cl_model = SimpleLinearClassifier()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compiling the pipeline\n",
        "\n",
        "As mentioned at the beginning, the greatest advantage of Keras over TensorFlow is that our processing pipeline is compiled on a static computational graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMwPvPZG_zPk",
        "outputId": "6449e553-2738-467f-9c64-0e30a536fecc"
      },
      "outputs": [],
      "source": [
        "model = fn_model\n",
        "help(model.compile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhvHTj_m_zPl"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=K.optimizers.Adam(learning_rate=0.1),\n",
        "    loss=K.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KMWbtPQ__zPl"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JU4l9sFW_zPl"
      },
      "source": [
        "Training a model with Keras is as simple as calling the `.fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5OQBSSN_zPl",
        "outputId": "f9ddf0c0-32b0-4b9e-f9a0-a5b91e07d603"
      },
      "outputs": [],
      "source": [
        "help(model.fit)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``callbacks`` parameter allows to add a list of functionalities which are called at specific times of the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping = K.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    patience=5,\n",
        "    min_delta=0.0005,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzFV8o1w_zPl",
        "outputId": "a806b6f8-41b1-4d9c-f708-59e50f6bf4d7"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x=train_X, \n",
        "    y=train_y, \n",
        "    epochs=100, \n",
        "    batch_size=1000,\n",
        "    validation_data=(eval_X, eval_y),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we have the additional advantage of the training history, providing statistics of the training phase useful for observing the behaviour of the model when the process is over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['loss'],\n",
        "    'val_loss': history.history['val_loss']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='loss value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['accuracy'],\n",
        "    'val_loss': history.history['val_accuracy']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='accuracy value')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_ayYvB_zPn"
      },
      "source": [
        "Keras models expose the method `.evaluate`, which returns the results of the metrics on a given dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj4Rc2Tj_zPn",
        "outputId": "56b5ba0e-eb8d-4016-9821-d745dd9dc252"
      },
      "outputs": [],
      "source": [
        "metrics = model.evaluate(test_X, test_y)\n",
        "metrics # loss, accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead, `.predict` returns the predictions of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_X)\n",
        "predictions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mxk-4jYSyaCP"
      },
      "source": [
        "## Model serialization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HBMcK8_nIf5F"
      },
      "source": [
        "A Keras Model can be easily `serialized` and `deserialized` as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEdOYZpCycm2"
      },
      "outputs": [],
      "source": [
        "model.save('my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = K.models.load_model('my_model')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-jZzBzQcg"
      },
      "source": [
        "There are several other options to serialize a model. It can be saved in H5 format, you can save only the parameters, only the model architecture etc..  \n",
        "You can find further details at the following webpage: https://www.tensorflow.org/guide/keras/save_and_serialize"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5gF499iBuw8l"
      },
      "source": [
        "# TensorBoard\n",
        "\n",
        "Monitoring your experiments is fundamental to have a deep comprehension of what's going on. The TensorFlow team developed TensorBoard, a framework-agnostic tool which monitors the desired metrics, plots them, and provides nice visualization options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYiCaNoPvLTD"
      },
      "outputs": [],
      "source": [
        "# this is only needed in a notebook\n",
        "%load_ext tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49jBCaVAv9IU"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = K.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.Rescaling(scale=1/255.))\n",
        "#model.add(K.layers.Dense(1000, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(200, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=K.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=K.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_X, \n",
        "    y=train_y, \n",
        "    epochs=10000, \n",
        "    batch_size=1000,\n",
        "    validation_data=(eval_X, eval_y),\n",
        "    callbacks=[early_stopping, tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your turn!\n",
        "\n",
        "Solve the excercise of Notebook 1 by using Keras.\n",
        "\n",
        "This time, instead of using the StandardScaler from sklearn, you have to use the [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization) layer. Pay attention to its usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h_train_X, h_train_y), (h_test_X, h_test_y) = tf.keras.datasets.boston_housing.load_data(\"./ds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "h_train = np.concatenate([h_train_X, h_train_y[:, np.newaxis]], axis=1)\n",
        "random.seed(42)\n",
        "random.shuffle(h_train)\n",
        "\n",
        "h_train, h_eval = h_train[75:], h_train[:75]\n",
        "h_train_X, h_train_y = h_train[:, :-1], h_train[:, -1]\n",
        "h_eval_X, h_eval_y = h_eval[:, :-1], h_eval[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h_train_X.shape, h_train_y.shape), (h_eval_X.shape, h_eval_y.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf_mela')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "3917c018cfd92834e25e8ac39593c8ba50cba5d103d91e5ca7d5a867c45ae1af"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
